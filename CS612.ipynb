{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15hoHxkyxACmlw-rIBOa1ZoJ5Wvc531HQ",
      "authorship_tag": "ABX9TyMgVnmovLBwsj0QddxamA80",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haridasaravind/CS612/blob/main/CS612.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K8ivuQU2crm",
        "outputId": "ff51c0a1-7048-4c92-b06f-e182e2670abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsHokfEO2mf6",
        "outputId": "4f666699-1bb3-4025-ab0e-47d99d775f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.81)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from Bio import SeqIO\n",
        "\n",
        "def read_fasta(directory='.'):\n",
        "    # Obtain a list of all files with the .fas extension in the specified directory\n",
        "    fas_files = [f for f in os.listdir(directory) if f.endswith('.fas')]\n",
        "    # Select a random .fas file from the list\n",
        "    selected_file = random.choice(fas_files)\n",
        "    print(f\"Selected File: {selected_file}\")\n",
        "\n",
        "    # Read the multiple sequence alignment (MSA) file\n",
        "    records = SeqIO.parse(os.path.join(directory, selected_file), \"fasta\")\n",
        "\n",
        "    # Dictionary to store sequences grouped by family\n",
        "    sequences_by_family = {}\n",
        "\n",
        "    # Process each sequence record\n",
        "    for record in records:\n",
        "        # Check if the record ID contains an underscore\n",
        "        if '_' in record.id:\n",
        "            # Extract family information from the record ID\n",
        "            family = record.id.split(\"_\")[1]\n",
        "\n",
        "            # Add the sequence to the corresponding family in the dictionary\n",
        "            if family in sequences_by_family:\n",
        "                sequences_by_family[family].append(record.seq)\n",
        "            else:\n",
        "                sequences_by_family[family] = [record.seq]\n",
        "        else:\n",
        "            print(f\"Warning: Skipping record with ID '{record.id}' because it does not contain an underscore\")\n",
        "\n",
        "    # Print summary statistics\n",
        "    total_sequences = sum(len(sequences) for sequences in sequences_by_family.values())\n",
        "    print(f\"Total sequences: {total_sequences}\")\n",
        "    \n",
        "    # Uncomment the following code to print the unique families\n",
        "    # print(f\"Total unique families: {len(sequences_by_family)}\")\n",
        "    # for family, sequences in sequences_by_family.items():\n",
        "    #     print(f\"Family {family}: {len(sequences)} sequences\")\n",
        "\n",
        "    # Uncomment the following code to print the sequences grouped by family\n",
        "    # for family, sequences in sequences_by_family.items():\n",
        "    #     print(f\"\\nFamily: {family}\")\n",
        "    #     for sequence in sequences:\n",
        "    #         print(sequence)\n",
        "    \n",
        "    return sequences_by_family\n",
        "\n",
        "sequences = read_fasta()\n",
        "\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pjbEgOe2s3Q",
        "outputId": "7ecd0fef-6604-45e6-b6b1-b633f1e36f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected File: YAGP_YAHO_20_id90.fas\n",
            "Warning: Skipping record with ID 'null' because it does not contain an underscore\n",
            "Total sequences: 143\n",
            "{'I5NWS5': [Seq('----------KEHGIPETPQELSNHNCLRLRH-KSG-ALAWEFSKGNEEFEIEV...KKK')], 'K4W2G4': [Seq('----------AQHGAPKHLTDLSALPCLERD----HPFGVWQL-RNKEHHAIKV...K--')], 'B2VGV9': [Seq('----------VQFGTPEKPSDIGNHSWLEYSV---RPDNDFELSPEGAIR-LSP...K--')], 'H7ECT9': [Seq('----------AQYGTPEKPADLSSHSWLEYSV---RPDNEFELAPEGSTR-LIP...K--')], 'B7NKX0': [Seq('---------ISRYGKPETIDDLKQHICLGFTE--PASLNTWPI-SDGQ-LH-EV...K--')], 'L2D3M5': [Seq('----------QKYPQPQSLQELSRHDCLERD----MTHGIWEL-GNGQKKSVKV...K--')], 'G2SCY6': [Seq('----------AQYGVPEKPADLSNHSWLEYSV---RPDNEFELAPEGSTK-LLP...K--')], 'L5VU34': [Seq('----------AQYGVPEKPADLSSHSWLEYSV---RPDNEFELAPEGSTR-LIP...K--')], 'I0MWA2': [Seq('---------IARFGKPETVEELKRHLCLGFSE--PVSLNTWPI-SDGQ-LH-EI...A--')], 'E0SFY2': [Seq('---------------------LFDHSLINFRLPTSGTLIGWPLMSDGREIRVRG...K--')], 'E0SEL1': [Seq('---------FAARGTPASPEALEDHDAVIYLQ-TDAP-GNWLFCRDDRQCRVTM...N--')], 'K8C201': [Seq('---------LERH-PISTPGALGSADWLVHTR--LASPLRWELGPQNETLWITR...S--')], 'L4BGC9': [Seq('---------ISCYGKPETIDDLKQHICLRFTE--PASLNTWPI-SDGQ-LH-EV...K--')], 'K8ZEJ7': [Seq('----------ALHPASVSDDMLRRYPAINIED--TSR----TLT-RRVAWLLSG...A--')], 'L3EIG0': [Seq('---------ISRYGKPETLDDLKQHVCLGFTE--PASLNTWPI-SDGQ-LH-EV...KKK')], 'K8BFS4': [Seq('---------LV----PVTLNDLSDHQCLGAR----G--ELMYWPSGD---RVKV...N--')], 'K8FM71': [Seq('----------AQHGAPKHLTDLSALPCLERD----HPFGVWQL-RNKEHHAIKV...A--')], 'K4S9X2': [Seq('----------ASHPVQT-LSDLAQAEWI--IH-ERP-TPRWQLRTHQTEVDFSI...K--')], 'K4SKA7': [Seq('---------VARYGMPQHPSDLKQHHCLGFTE--PVSLNTWPVSC-CDGQLLEI...K--')], 'K0XGW6': [Seq('----------AQHGALKHLTDLSALPCLERD----HPFGVWQL-RNKEHHAIKV...K--')], 'J2QSR6': [Seq('----------AQAGNPEKPADLAGHAWLEYSV---RPDNEFVIAPEGSTR-LTP...K--')], 'K5IC34': [Seq('----------RRYGFPQTPADLKAHPCIAYQF-ADG-SVQWELN-QDKKITHQP...R--')], 'C9XTI2': [Seq('----------AQAGTPEKPADLANHSWLEYSV---RPDNEFELAPEGSTR-LLP...K--')], 'K4ZZA4': [Seq('----------AQYGVPEKPADLSSHSWLEYSV---RPDNEFELAPEGSTR-LIP...K--')], 'E8XRI1': [Seq('----------QRKGTPEMPEDLLNHHCLRYG--REGQTG-WELELEGKRRLFDV...KKK')], 'E8XPF8': [Seq('---------FAANPAPETPHELQNHRCINMRL--PTGLYHWEFEREGKPLRVRV...K--')], 'E0LSN9': [Seq('---------IAQNGMPETPDDLQRHPHIRFSG-ISPDA-PLQLVSMTSV-SVPV...K--')], 'K6KRC6': [Seq('---------LTRFGYPQSLDDLADHALIHYASNLGVRPLGFEVVSDGAVRWVKA...K--')], 'G8WG94': [Seq('---------FAANPAPETPHELQNHRCINMRL--PTGLYHWEFEKDGKPLRVRV...K--')], 'L4H8M6': [Seq('---------ISRYGKPETIDDLKQHVCLGFTE--PASLNTWPI-SDGQ-LH-EV...K--')], 'D1S0Z5': [Seq('---------LARHPV-GSLTQLAQAQWIAHS-R-LSSPLSWQVITPQRQLKVED...L--')], 'D1RNI7': [Seq('----------ARQGEPGAVAELLQHQAIAMLR-DGHSQ-PWELLDQG-KTRLQP...N--')], 'K8DU54': [Seq('------------------IDELAALPWVALS-----TFYRREVTTSGERQTFTV...K--')], 'C6CQ57': [Seq('---------FAAHGLPASPEALENHDAVLYLQ-A--DTGNWRFRRDDRQCQVTL...N--')], 'C6CFT6': [Seq('---------------------LRDHRCIGYRF-VSRSLHRWRFLRGDQDLLTDF...N--')], 'C6CKU6': [Seq('----------RHYGFPQTPADLVVHPCIAYQF-ADG-SLHWELW-QGKRLRHKP...N--')], 'K4RTI8': [Seq('---------VARYGMPQHPSDLKQHHCLGFTE--PVSLNTWPVSC-CDGQLLEI...Q--')], 'E1HMK5': [Seq('----------AQHGAPKHLTDLSALPCLERD----HPFGVWQL-RNKEPHAIKV...KKK')], 'D3UZ04': [Seq('----------RLHGELQHPEELINHHCLLFSA--SGKS-TWSLH-DRGTKAISL...K--')], 'G5M8X7': [Seq('----------AQYGVPEKPADLSSHSWLEYSV---RPDNEFELAPEGSTR-LIP...K--')], 'E9A6F2': [Seq('----------EQHPDLKTIGDLHRAPAMVRLA-DGRMQ-SWHLI-GS-QETLSL...K--')], 'D2BSU0': [Seq('---------FARYGVPDTPHDLQHHRCINMRL--PTGLYHWEFEKDGKPLQVKV...K--')], 'D2C3A2': [Seq('---------------------LSEHRCISYRQ-SGGGIYAWEFEKEGDALEVRV...R--')], 'D2BVX6': [Seq('---------FRHYGFPQTPADLVVHPCIAYQF--AGSLYQWELWQDGKPLRHKP...N--')], 'D2BZR1': [Seq('----------AAHGTPTSPDALEHHDAVIYLQ-D-EGS--VCFQKGDRQHRVTL...N--')], 'I2T0G0': [Seq('---------FARYGKPRHPHDLLNHQCVVFRY--PSKPFHWQF--AKE-LEIAV...K--')], 'L2W825': [Seq('MPAPVVLILAAGRGKRFLASEGNTHKCIGWRQSPEVAPYRWPFEENGRTFDLAI...K--')], 'H5V5L2': [Seq('----------SRHGTPEKPSDLGNHSWLEYSV---RPDNEFELAPEGSTR-LIP...K--')], 'J7GG24': [Seq('---------LKNHGVPAYPQELRGHKLISY-P-VTGRAFPFRFRQDGEALEISI...K--')], 'A8GK90': [Seq('----------QQYPSLQQPEQLVSHAGIFIRSPQTGRVRNLPLRNADEQRAPSM...N--')], 'A8GBL3': [Seq('---------LAQQGVPTQPEQLSAHSCFGFSQ-WD-GNHFWRLQGPTGEISVPV...Q--')], 'L4IK28': [Seq('----------KEHGIPETPQELSNHNCLRLRH-KSG-ALAWEFSNGNEEFEIEV...K--')], 'D4HUV9': [Seq('----------LQFGTPEKPSDISNHSWLEYSV---RPDNDFDLSPEGAIR-LSP...K--')], 'I2TCW3': [Seq('---------ISRYGKPETIDDLKQHVCLGFTE--PASLNTWPI-SDGQ-LH-EV...K--')], 'L6AVS7': [Seq('----------ARMGIPSAPAELSHWPGL--SL-ASK-HIRWELYGQGARAEVHF...K--')], 'L4A4V8': [Seq('----------KEHGIPETPQELSNHNCLRLRH-KSG-ALAWEFSNGNEEFEIEV...A--')], 'G0BHX6': [Seq('----------AQHGAPTRPEQLSEHSCFGFSQ--WDNH-FWRLQGQG-EISVPV...Q--')], 'K1NCX2': [Seq('----------REAGEPDTPQSLVNFRCINRCF-PDGEY-RWEFIG-PGELEVAV...A--')], 'K8CZ77': [Seq('---------LARHPPVEDIDSLAALPWVTFYR-R-----EVTLHHSGEQ-AFTV...K--')], 'L1WVD4': [Seq('---------FARYGKPRHPHDLLNHQCVVFRY--PSKPFHWQF--AKE-LEIAV...K--')], 'G4KDB1': [Seq('---------LQRHGTPHTIDDLANHSLLGFTQ--PEFLNQWSL-LPGG-RT-SI...K--')], 'B0GDR6': [Seq('----------QRYGTPKALSELPGFACLVIKE-RDHPFGIWRLH-NGEEQSIKV...K--')], 'H8DQW1': [Seq('----------AQHGTPEKPGDIDNFSWLEYSV---RPDNNFELAPEGVTR-LAP...K--')], 'B0HNW6': [Seq('---------FMANAIPVTPHELQHHRCINMRL--PTGLYHWEFEKEGKPLRVKV...K--')], 'I0QSY2': [Seq('---------LEKNGPLSVPADLVNHRCLGFAH-PVA-GNEWLLQGLDGPISVPV...K--')], 'I0QS61': [Seq('----------AAHGVPRHPNDLSAHDCLYYPR-GTEPR--WIFEEMS-QLKVNV...---')], 'J1NV09': [Seq('---------IARFGKPESVEELKQHLCLGFSE--PISLNTWPI-SDGQ-LH-EI...K--')], 'L6MML4': [Seq('----------ERHGKPESVSALVQHDCLMIQEKNSAGN--WILT-DGQQTHCRL...R--')], 'K4SZ42': [Seq('---------IRRHGMLGSPEELARHKCL-VYRG-SSGPNQWLLRHGEEWVHYPV...K--')], 'K4T221': [Seq('----------ASHPVQT-LSDLAQAEWI--IH-ERP-TPRWQLRTHQTEVDFSI...K--')], 'J2IN27': [Seq('---------------------LHQHECINFRL-SSGGIYCWEFARAGQEIKVKV...K--')], 'L5YN13': [Seq('----------RKYGRISHPGDLENHIIVGLNHGLSG-PLTL-FR-QDESIAVNV...KKK')], 'B3B746': [Seq('----------TQYGIPEKPADLSSHSWLEYSV---RPDNEFELAPEGSTR-LIP...K--')], 'L6KSB4': [Seq('----------ARHPVS-SLESLAQAEWIIHER--LPTPLRWSVTNNHGQHSISK...K--')], 'G9SFV4': [Seq('--------------V-QAQCDLPACELI-HPS-ADRRDWRW-LQ-RGPALNLA-...KKK')], 'L0WWX0': [Seq('----------LQFGTPEKPSDISNHSWLEYSV---RPDNDFDLSPEGAIR-LSP...Q--')], 'E6A316': [Seq('---------FAANPAPETPHELQNHRCINMR---LPTAGGW-EFERGKPLRVKV...K--')], 'A9MMV2': [Seq('---------PFADRKSVTFLELMEYEQISLPE--GTGMFEF-IRKKAELVQSKL...KKK')], 'E6WN15': [Seq('---------FAQHGLPETPYELQNHNCINMRL--PTGIYSWEFYKDGKEIRVKV...K--')], 'E6WGF6': [Seq('----------AQHGTPEKPGEIDNFSWLEYSV---RPDNTFELAPEGVTR-LTP...K--')], 'E6WH26': [Seq('------------AEENASAESLLHHMLLIQDD-PQREWSDWF--ASQDVLSFVP...K--')], 'K8QVW3': [Seq('----------AKKGMPQRRSDLVDHDCLVYP--GLTP--VLKVADEQRLHQLKL...K--')], 'K8QPT8': [Seq('----------AQFGTPEKPADLSNHSWLEYSV---RPDNEFELAPEGSTR-LIP...K--')], 'L3RST1': [Seq('---------FRRYGFPQTPADLKAHPCIAYQF--AGSVYQWELNQDDKKITHRP...KKK')], 'I6W0T4': [Seq('---------LKTRHLH-SYSELCGLRLLHSM---PQN--AWRYFALGLY-DLNV...K--')], 'G8W1E5': [Seq('----------AQAGNPEKPADLAGHAWLEYSV---RPDNEFVIAPEGSTR-LTP...K--')], 'A8AQD8': [Seq('----------AQFGVPEKPADLSNHSWLEYSV---RPDNEFELAPEGSTR-LIP...K--')], 'E9Z4P1': [Seq('---------FAANALPETPHELQNHQCINMRL--PTGIYHWEFEREGKPLRVRV...KKK')], 'C6C684': [Seq('-------------------PEIEQQDAIVYLQSSTPEN--WLFSRGAQQCRVTL...K--')], 'L6RMD3': [Seq('----------ARHPVS-SLESLAQAEWIIHER--LPTPLRWSVTNNHGQHSISK...K--')], 'G9W0T1': [Seq('---------LERHGKPESVSALVQHDCLMIQE--KNSAFGWILTDGKQQTHCRL...KKK')], 'H2IYJ3': [Seq('----------QKHGVPEHPQDLRDHTLVQIASPQTGRVFEHQVFKDEQSVTVRG...K--')], 'H3RHJ6': [Seq('----------AQHGTPEKPADITKFAWLEYSV---RPDNNFELAPEGVTR-LSP...K--')], 'I2SAJ6': [Seq('----------TQYGIPEKPADLSSHSWLEYSV---RPDNEFELAPEGSTR-LIP...A--')], 'I2S6J9': [Seq('---------LTRFGYPQSPDDLTSHAIVRYTP-HLGVH-PFEVASNGVQ-WFKS...R--')], 'K4YRT1': [Seq('---------LERLGAPAHPRELENHRIVGFLSSRTGKIDPLVLRSESEHIDITG...KKK')], 'I2YVZ5': [Seq('---------FSRRSAPTSVSQLIDHQAINYLPT-SGTANRWRLIRGGREVRVRM...K--')], 'L5Y7V7': [Seq('---------------------LINHRCLCHRFTRESGLYRWEFVHGAQRLEITP...N--')], 'K1N3W3': [Seq('---------LREYGVPPSPEALSQHRAVHYFSGQARRADEFRFVRHGETFSVPV...K--')], 'F5S2J5': [Seq('----------AQYGVPEKPADLSNHSWLEYSV---RPDNEFELAPEGSTK-LLP...K--')], 'L3EJB5': [Seq('---------ISRYGKPETIDDLKQHICLGFTE--PASLNTWPI-SDGQ-LH-EV...R--')], 'E3GCQ0': [Seq('----------QQAGTPEKPADLASHSWLEYSV---RPYNEFELGPEGATR-LTP...K--')], 'E3G8A7': [Seq('---------LAMHGVPQTADDLSAHLCLGFTE--PVSLNTWPL-ARYDGQLLEV...-K-')], 'B5MUA1': [Seq('---------IARFGKPETVEELKRHLCLGFSE--PVSLNTWPI-SDGQ-LH-EI...R--')], 'G9USB7': [Seq('---------IARFGKPETVEELKRHLCLGFSE--PVSLNTWPI-SDGQ-LH-EV...K--')], 'L5XMK2': [Seq('---------IARFGKPESVEELKQHLCLGFSE--PISLNTWPI-SDGQ-LH-EI...KKK')], 'L5XN79': [Seq('----------ERHGKPESVSALVQHDCLMIQEKNSAGN--WILT-DGQQTHCRL...A--')], 'A1JU50': [Seq('---------LARNGVPQTPAQLVNHQSVLYQ---RNGRLNWRLMRQDDIQEVTM...N--')], 'L3HUF2': [Seq('---------FARYGKPRHPHDLLNHQCVVFRY--PSKPFHWQF--AKE-LEIAV...K--')], 'Q1R582': [Seq('---------LTRFGYPQSPDDLTSHAIVRYTP-HLGVH-PFEVASNGVQ-WFKS...K--')], 'E7B500': [Seq('---------LAQHPPLLHPRQLDTHRCIAH-----RAWQALILRHEDEFFRWQV...K--')], 'G0GRD3': [Seq('---------VAKNGLPDSVESLAHHHCIQYRY--PGRLEAWPLEEYRGS--LSF...---')], 'D7ZNQ5': [Seq('---------LTRFGYPQSPDDLTSHAIVRYTP-HLGVH-PFEVASNGVQ-WFKS...A--')], 'L3WCI1': [Seq('---------FSRRSAPTSVSQLIDHQAINYLPT-SGTANRWRLIRGGREVRVRM...K--')], 'J2LD96': [Seq('----------AQHGTPEKPGEIDNFSWLEYSV---RPDNTFELAPEGVTR-LTP...N--')], 'D4DWH9': [Seq('---------VRALGDVRQPEDLLRYPTLDLGP--ARPQHQWTLGPDTRRFDWEH...R--')], 'D4E980': [Seq('---------PLANAAQIGLSDVSEEPWVLFPA--HYGMHAA-ILQACAMAGFTP...K--')], 'C4SPA6': [Seq('--------YFKNHSRPKTPQELTTHNCMNLRLPTRGGLYLWELEKEGQKLQVRV...R--')], 'K8A8Q9': [Seq('---------LARHGTPEHPQELRQHSCISLGE-T-AAD--WKFRDGKSVV-VQT...S--')], 'C4TYC8': [Seq('---------FTAYGYPQDWQELTEHRTIGQ----LGHNEPWRLDNHGQIHWMSP...N--')], 'C4UCH0': [Seq('---------LHRHGTPLTIDQLADHSLLGFTQ--PESLNQWSL-LPAG-RS-AI...R--')], 'L5Z5H8': [Seq('---------PFADRKSVTFHELIQYEQISLPE--GTGMFEF-IRKKAELVPSKL...K--')], 'J9ZSG4': [Seq('MPAPVVLILAAGRGERFLASGGNTHKCIGWRQSPEVAPYRWPFEENGRTFDLAI...R--')], 'L0W6D4': [Seq('---------LAKISPPTHVQDLSALNSLVFAYPG-YNSAYWTLEE-NGEVRVPV...K--')], 'D2TUF6': [Seq('---------PLAERDELKFEDILYEKLIGSHR--NSAVSYI-LERQARAYGKTL...N--')], 'L0LY03': [Seq('----------QHAGIPEKPADLANHSWLEYSV---RPDNEFELAPEGTTR-LIP...K--')], 'L0M7V1': [Seq('----------ARHGTPQTLDDL-YHQAINIVS-NNREIVPWHFTTPQGVEERVL...A--')], 'L0RTP9': [Seq('---------LAQHPPLLHPRQLDTHRCIAH-----RAWQALILRHEDEFFRWQV...R--')], 'F2EVR6': [Seq('----------TQHGTPEKPGDITKFAWLEYSV---RPDNNFELAPEGVTR-LSP...K--')], 'D4BAT9': [Seq('---------------------LAGHNCIRRRFE-SGRVYRWELAHDGRAITVDV...K--')], 'H3LM95': [Seq('---------IAAHGRPETLDQLEQHRAVGY-H-RTGRSIEWHFSLAEGDYALRM...---')], 'D8MXP0': [Seq('----------TQHGTPEKPSDLGNFSWLEYSV---RPDNDFELSPEGSIR-LSL...K--')], 'I1B4B2': [Seq('---------LTRFGYPQSPDDLTSHAIVRYTP-HLGVH-PFEVASNGVQ-WFKS...K--')], 'L3HPW8': [Seq('---------FSRRSAPTSVSQLIDHQAINYLPT-SGTANRWRLIRGGREVRVRM...KKK')], 'G0B8L7': [Seq('----------RRHPLLSQPEQLANHAGIFIRSPQTGRIRNLPLRNADEQRAPLM...N--')], 'G0B9R7': [Seq('---------VRTLGPVQRPDELDKYPTLDLGP--ARAQHQWQLTGPAEKVEWEH...R--')], 'G9Z264': [Seq('----------QQAGIPEKPADLANHSWLEYSV---RPHNDFELAPEGTTR-LSP...K--')], 'I2B948': [Seq('---------LEKYGAPRSLEDLANMPVLGVSQ--QDERMYWRLTNPQEAQLFSY...---')], 'I2B3T7': [Seq('--------------------DLAGRECILWFR-NEHIHNAWSFSGAAGQQTIIV...K--')], 'I3AHD1': [Seq('---------MRTLGPVQRPEELDKYPTLDLGP--ARAQHQWQLTGPDEKVEWEH...R--')], 'K4UDA4': [Seq('---------LAAHGRPQSIDELHQHRAVGY-H-RTGRTIDWLFSLDEGDCAIRM...Q--')], 'L7BGH3': [Seq('---------------------LINHRCLCHRFTRESGLYRWEFVHGAQRLEITP...A--')], 'K4H529': [Seq('---------LAKYPPLTSLEALSGLPWITFYQ-H-----EVRLRHSGQV-STAI...K--')]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def read_sequence(sequences):\n",
        "    # Flatten the list of sequences\n",
        "    all_sequences = [seq for seq_list in sequences.values() for seq in seq_list]\n",
        "    # Select a random sequence from the list\n",
        "    return random.choice(all_sequences)\n"
      ],
      "metadata": {
        "id": "yNwGEgXm270-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq = read_sequence(sequences)\n",
        "print(seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLvZUcM73f-Z",
        "outputId": "bbf76430-8c5f-4b8c-d7ba-b64a36bae126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------LTRFGYPQSLDDLADHALIHYASNLGVRPLGFEVVSDGAVRWVKAGGVLTVNSTETYQASCLAGLGIIQVPRIGVREMLRTGELIEILPHYRAEPLPVSLIYPHRRNLSRRVHLFMEWLGGMM----MKFVTGIVASLVGLSFG-AFAAKEIQKD---E-VANLTKIGSITTS-RTSPMDAKRDLSKKADELGGTYFVVIAGEKNEKVHANADVYK--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import amin\n",
        "import numpy as np\n",
        "\n",
        "def one_hot_encoding(seq):\n",
        "    # Define the amino acid alphabet\n",
        "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "    # Create a dictionary to map each amino acid to its index in the alphabet\n",
        "    aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
        "    # Initialize the one-hot encoded array\n",
        "    one_hot = np.zeros([len(seq), len(amino_acids)])\n",
        "    # Set the appropriate elements to 1\n",
        "    for i, aa in enumerate(seq):\n",
        "      if aa in aa_to_index:\n",
        "        one_hot[i, aa_to_index[aa]] = 1\n",
        "    return one_hot\n"
      ],
      "metadata": {
        "id": "7JT9bogS3gRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = one_hot_encoding(seq)\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "print(one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qbMStla33cs",
        "outputId": "1ab19494-eeb4-4781-b01e-f074913cddb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Autoencoder\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# Define the amino acid alphabet\n",
        "amino_acids = 'ACDEFGHIKLMNPQRSTVWY-'\n",
        "\n",
        "def one_hot_encoding(seq):\n",
        "    # Create a dictionary to map each amino acid to its index in the alphabet\n",
        "    aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
        "    # Initialize the one-hot encoded array\n",
        "    one_hot = np.zeros((len(seq), len(amino_acids)))\n",
        "    # Set the appropriate elements to 1\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa in aa_to_index:\n",
        "            one_hot[i, aa_to_index[aa]] = 1\n",
        "    return one_hot\n",
        "\n",
        "# Define the size of the latent space\n",
        "latent_dim = 32\n",
        "\n",
        "# Define the architecture of the autoencoder\n",
        "input_seq = Input(shape=(None, len(amino_acids)))\n",
        "encoded = Dense(latent_dim, activation='relu')(input_seq)\n",
        "decoded = Dense(len(amino_acids), activation='softmax')(encoded)\n",
        "autoencoder = Model(input_seq, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')\n"
      ],
      "metadata": {
        "id": "w5p9UGyg33gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the sequence using one-hot encoding\n",
        "seq_encoded = one_hot_encoding(seq).reshape(1, -1, len(amino_acids))"
      ],
      "metadata": {
        "id": "zhGtT0u34RRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the autoencoder on the encoded sequence\n",
        "#autoencoder.fit(seq_encoded, seq_encoded, epochs=100)\n",
        "history = autoencoder.fit(seq_encoded, seq_encoded, epochs=100)\n",
        "loss_values = history.history['loss']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWZhT6g44RUT",
        "outputId": "ca369e3e-e00b-4faa-8c0d-b0550d25886e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 642ms/step - loss: 3.0957\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.0889\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0822\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0755\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.0689\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.0622\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0556\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0490\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0424\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0357\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0291\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0225\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.0159\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0093\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.0027\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.9961\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.9896\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9830\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.9764\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9699\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9634\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9569\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9504\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.9439\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.9373\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.9308\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.9243\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.9177\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9112\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.9046\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.8981\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8915\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8849\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.8783\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8717\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8650\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.8583\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.8516\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.8449\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.8382\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.8314\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.8246\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.8177\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8108\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8039\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7970\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7900\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7830\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7759\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7687\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7615\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7543\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7470\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7397\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7323\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7249\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7174\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7099\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7024\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6948\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6871\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6795\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6718\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6640\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6562\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6483\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6404\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6324\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6244\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6164\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6083\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6002\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5920\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5838\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5755\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5672\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5588\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5504\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5419\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5333\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5247\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5161\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5074\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4986\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4897\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4808\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4718\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4628\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4537\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4445\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4353\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4260\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4167\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4072\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3977\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3880\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3784\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3686\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3588\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "mCA6tnx7S4Yz",
        "outputId": "514fe34b-0a31-4de3-fc10-e34100a7d67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the autoencoder to encode and decode the sequence\n",
        "seq_decoded = autoencoder.predict(seq_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqNhNzaG4RX2",
        "outputId": "a5871aa0-1d7e-4eb2-997d-7c4ce448b70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute reconstruction error metrics\n",
        "cross_entropy = -np.mean(np.sum(seq_encoded * np.log(seq_decoded), axis=-1))\n",
        "same_aa_accuracy = np.mean(np.argmax(seq_encoded, axis=-1) == np.argmax(seq_decoded, axis=-1))\n",
        "most_common_aa_accuracy = np.mean(np.argmax(seq_encoded.sum(axis=0), axis=-1) == np.argmax(seq_decoded.sum(axis=0), axis=-1))"
      ],
      "metadata": {
        "id": "IIpsMeUq32VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cross-entropy:\", cross_entropy)\n",
        "print(\"Same amino acid accuracy:\", same_aa_accuracy)\n",
        "print(\"Most common amino acid accuracy:\", most_common_aa_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAArhWLM42kD",
        "outputId": "c933d85d-a0af-4819-e5ae-ed2470cdb8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-entropy: 2.3390187523963695\n",
            "Same amino acid accuracy: 0.9559471365638766\n",
            "Most common amino acid accuracy: 0.9559471365638766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decoding\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "amino_acids = 'ACDEFGHIKLMNPQRSTVWY-'\n",
        "\n",
        "def one_hot_encoding(seq):\n",
        "    # Define the amino acid alphabet\n",
        "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY-'\n",
        "    # Create a dictionary to map each amino acid to its index in the alphabet\n",
        "    aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
        "    # Initialize the one-hot encoded array\n",
        "    one_hot = np.zeros((len(seq), len(amino_acids)))\n",
        "    # Set the appropriate elements to 1\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa in aa_to_index:\n",
        "            one_hot[i, aa_to_index[aa]] = 1\n",
        "    return one_hot\n",
        "\n",
        "def decode_sequence(one_hot_seq):\n",
        "    # Define the amino acid alphabet\n",
        "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY-'\n",
        "    # Convert the one-hot encoded sequence back into an amino acid sequence\n",
        "    return ''.join([amino_acids[i] for i in np.argmax(one_hot_seq, axis=-1)])\n",
        "\n",
        "# Define the size of the latent space\n",
        "latent_dim = 32\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "input_seq = Input(shape=(None, len(amino_acids)))\n",
        "encoded = Dense(latent_dim, activation='relu')(input_seq)\n",
        "decoded = Dense(len(amino_acids), activation='softmax')(encoded)\n",
        "autoencoder = Model(input_seq, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "\n",
        "# Encode the sequence using one-hot encoding\n",
        "seq_encoded = one_hot_encoding(seq).reshape(1, -1, len(amino_acids))\n",
        "\n",
        "# Train the autoencoder on the encoded sequence\n",
        "autoencoder.fit(seq_encoded, seq_encoded, epochs=100)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHqKlLAz42mh",
        "outputId": "285c0e58-5d4d-49ba-f124-686cf1b43a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 2.9676\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.9605\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9534\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9463\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9392\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9320\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9249\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9178\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9106\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9035\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8963\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8892\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8820\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8748\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8676\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8604\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8532\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8459\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8387\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8314\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8241\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8168\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8095\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8022\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7948\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7874\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7801\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7727\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7653\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7578\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7503\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7428\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7353\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7277\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7200\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7123\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7045\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6967\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6888\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6808\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6728\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6648\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6567\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6485\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6403\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6321\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.6238\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6155\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6071\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5986\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5901\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5815\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5728\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5641\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5553\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5464\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5375\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5286\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5196\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5105\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5014\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4922\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4829\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4736\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4643\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4549\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4454\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4359\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4263\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4167\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4071\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3973\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3876\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3777\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3678\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3579\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3479\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3378\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3277\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3175\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3073\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2970\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2867\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2763\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2658\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2553\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2447\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2340\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2233\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2126\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2018\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1910\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1801\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1692\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1582\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1472\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1361\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1250\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1139\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1026\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f20dae85fc0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decoding\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "amino_acids = 'ACDEFGHIKLMNPQRSTVWY-'\n",
        "\n",
        "def one_hot_encoding(seq):\n",
        "    # Define the amino acid alphabet\n",
        "    \n",
        "    # Create a dictionary to map each amino acid to its index in the alphabet\n",
        "    aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
        "    # Initialize the one-hot encoded array\n",
        "    one_hot = np.zeros((len(seq), len(amino_acids)))\n",
        "    # Set the appropriate elements to 1\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa in aa_to_index:\n",
        "            one_hot[i, aa_to_index[aa]] = 1\n",
        "    return one_hot\n",
        "\n",
        "def decode_sequence(one_hot_seq):\n",
        "    # Define the amino acid alphabet\n",
        "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY-'\n",
        "    # Convert the one-hot encoded sequence back into an amino acid sequence\n",
        "    return ''.join([amino_acids[i] for i in np.argmax(one_hot_seq, axis=-1)])\n",
        "\n",
        "# Define the size of the latent space\n",
        "latent_dim = 32\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "input_seq = Input(shape=(None, len(amino_acids)))\n",
        "encoded = Dense(latent_dim, activation='relu')(input_seq)\n",
        "decoded = Dense(len(amino_acids), activation='softmax')(encoded)\n",
        "autoencoder = Model(input_seq, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "# Encode the sequence using one-hot encoding\n",
        "seq_encoded = one_hot_encoding(seq).reshape(1, -1, len(amino_acids))\n",
        "\n",
        "# Train the autoencoder on the encoded sequence\n",
        "autoencoder.fit(seq_encoded, seq_encoded, epochs=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cRlQXxKj687",
        "outputId": "9eb849aa-93e8-4537-c3ad-5011ef91cc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 3.0436\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0368\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0300\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0232\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0164\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0097\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0029\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9962\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9895\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.9828\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9761\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9694\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9627\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9561\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9494\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9428\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9361\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9294\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9228\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9161\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9094\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9026\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8959\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8892\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8824\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8756\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8688\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8620\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8552\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8483\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8415\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8346\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8277\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8207\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8138\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8068\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7998\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7928\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7858\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7787\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7715\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7643\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7571\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7499\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7426\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7352\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7278\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7203\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7128\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7053\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6977\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6901\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6824\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6746\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6668\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6589\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6509\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6429\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6348\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6267\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6185\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6103\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6019\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5936\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5851\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5766\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5680\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5594\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5507\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5419\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5331\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5242\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5152\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5062\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4970\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4878\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4785\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4691\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4597\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4502\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4407\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4310\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4213\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4115\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4017\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3918\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3819\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3718\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3617\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3516\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3413\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3310\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3206\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3102\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2997\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2891\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2785\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2678\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2570\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2461\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f20d9f6cca0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the autoencoder to encode and decode the sequence\n",
        "seq_decoded = autoencoder.predict(seq_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945Ir2lZ42op",
        "outputId": "fcba34a4-958d-41ef-f7e6-7ce6266c9de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 139ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute reconstruction error metrics\n",
        "cross_entropy = -np.mean(np.sum(seq_encoded * np.log(seq_decoded), axis=-1))\n",
        "#  print(np.sum(seq_encoded * np.log(seq_decoded), axis=-1)) \n",
        "same_aa_accuracy = np.mean(np.argmax(seq_encoded, axis=-1) == np.argmax(seq_decoded, axis=-1))\n",
        "most_common_aa_accuracy = np.mean(np.argmax(seq_encoded.sum(axis=0), axis=-1) == np.argmax(seq_decoded.sum(axis=0), axis=-1))\n",
        "\n",
        "print(\"Cross-Entropy:\", cross_entropy)\n",
        "print(\"Accuracy (Same aa):\", same_aa_accuracy)\n",
        "print(\"Accuracy (Mode aa):\", most_common_aa_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9F3qxYT42rV",
        "outputId": "73ee487e-b04d-4757-9856-ea4b5767d5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Entropy: 2.1999015109654567\n",
            "Accuracy (Same aa): 0.9074889867841409\n",
            "Accuracy (Mode aa): 0.9074889867841409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode and print the original and reconstructed sequences\n",
        "print(\"Original sequence:\")\n",
        "print(decode_sequence(seq_encoded[0]))\n",
        "print(\"Reconstructed sequence:\")\n",
        "print(decode_sequence(seq_decoded[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulRs2c4Y42t9",
        "outputId": "5ffeee2c-2d53-4892-8c68-eb7b23bc6543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sequence:\n",
            "---------LTRFGYPQSLDDLADHALIHYASNLGVRPLGFEVVSDGAVRWVKAGGVLTVNSTETYQASCLAGLGIIQVPRIGVREMLRTGELIEILPHYRAEPLPVSLIYPHRRNLSRRVHLFMEWLGGMM----MKFVTGIVASLVGLSFG-AFAAKEIQKD---E-VANLTKIGSITTS-RTSPMDAKRDLSKKADELGGTYFVVIAGEKNEKVHANADVYK--\n",
            "Reconstructed sequence:\n",
            "---------LTRFGYVVSLDDLADIALIIYASNLGVRVLGFEVVSDGAVRRVKAGGVLTVNSTETYVASPLAGLGIIVVVRIGVREMLRTGELIEILVIYRAEVLVVSLIYVIRRNLSRRVILFMERLGGMM----MKFVTGIVASLVGLSFG-AFAAKEIVKD---E-VANLTKIGSITTS-RTSVMDAKRDLSKKADELGGTYFVVIAGEKNEKVIANADVYK--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Autoencoder for other amion acids \n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# Define the amino acid alphabet\n",
        "amino_acids = 'S A G N G N Y E R A G I-'\n",
        "\n",
        "def one_hot_encoding(seq):\n",
        "    # Create a dictionary to map each amino acid to its index in the alphabet\n",
        "    aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
        "    # Initialize the one-hot encoded array\n",
        "    one_hot = np.zeros((len(seq), len(amino_acids)))\n",
        "    # Set the appropriate elements to 1\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa in aa_to_index:\n",
        "            one_hot[i, aa_to_index[aa]] = 1\n",
        "    return one_hot\n",
        "\n",
        "# Define the size of the latent space\n",
        "latent_dim = 32\n",
        "\n",
        "# Define the architecture of the autoencoder\n",
        "input_seq = Input(shape=(None, len(amino_acids)))\n",
        "encoded = Dense(latent_dim, activation='relu')(input_seq)\n",
        "decoded = Dense(len(amino_acids), activation='softmax')(encoded)\n",
        "autoencoder = Model(input_seq, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')\n"
      ],
      "metadata": {
        "id": "SGGayNQGVU7S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}